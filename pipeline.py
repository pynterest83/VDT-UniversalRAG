import uuid
from typing import TypedDict, List, Optional
import os
from dotenv import load_dotenv

load_dotenv()

from langgraph.graph import StateGraph, END, START

os.environ["LANGCHAIN_TRACING_V2"] = "false"

class GraphState(TypedDict):
    """
    Äá»‹nh nghÄ©a cáº¥u trÃºc dá»¯ liá»‡u cho toÃ n bá»™ pipeline.

    Attributes:
        question: CÃ¢u há»i gá»‘c tá»« ngÆ°á»i dÃ¹ng.
        entities: CÃ¡c thá»±c thá»ƒ (keyword, topic) Ä‘Æ°á»£c LLM trÃ­ch xuáº¥t.
        text_chunks: Danh sÃ¡ch cÃ¡c Ä‘oáº¡n vÄƒn báº£n truy xuáº¥t Ä‘Æ°á»£c.
        image_url: URL cá»§a hÃ¬nh áº£nh Ä‘Æ°á»£c tÃ¬m tháº¥y hoáº·c sinh ra.
        final_answer: CÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng cho ngÆ°á»i dÃ¹ng.
        error: ThÃ´ng bÃ¡o lá»—i náº¿u cÃ³.
    """
    question: str
    entities: Optional[dict]
    text_chunks: Optional[List[dict]]
    image_url: Optional[str]
    final_answer: Optional[str]
    error: Optional[str]


# --- 2. CÃ¡c hÃ m giáº£ láº­p (Mock Functions) ---
# Thay tháº¿ cÃ¡c hÃ m nÃ y báº±ng cÃ¡c lá»i gá»i API/logic thá»±c táº¿ cá»§a báº¡n.

def mock_llm_extract_entities(question: str) -> dict:
    """Giáº£ láº­p viá»‡c gá»i LLM Ä‘á»ƒ trÃ­ch xuáº¥t entities."""
    print("ğŸ¤– >> Giáº£ láº­p LLM: Äang trÃ­ch xuáº¥t entities...")
    if "bÃ¡ch tháº£o sÆ°Æ¡ng" in question.lower():
        return {"keyword": "BÃ¡ch tháº£o sÆ°Æ¡ng", "topic": "cháº£y mÃ¡u chÃ¢n rÄƒng"}
    return {"keyword": "unknown", "topic": "general"}

def mock_text_hybrid_search(question: str, entities: dict, k: int = 3) -> List[dict]:
    """Giáº£ láº­p viá»‡c tÃ¬m kiáº¿m vÄƒn báº£n káº¿t há»£p (vector + filter)."""
    print(f"ğŸ“„ >> Giáº£ láº­p VectorStore: Äang tÃ¬m kiáº¿m vÄƒn báº£n vá»›i filter '{entities}'...")
    # Trong thá»±c táº¿, báº¡n sáº½ dÃ¹ng entities Ä‘á»ƒ táº¡o metadata filter
    return [
        {
            "chunk_id": "chunk_xyz_789",
            "content": "Äá»ƒ chá»¯a chá»©ng káº½ rÄƒng ra mÃ¡u, dÃ¹ng má»™t Ã­t BÃ¡ch tháº£o sÆ°Æ¡ng lÃ m ra bá»™t, xÃ¡t trá»±c tiáº¿p vÃ o chÃ¢n rÄƒng.",
            "metadata": {"keyword": "BÃ¡ch tháº£o sÆ°Æ¡ng", "source": "Táº­p giáº£n phÆ°Æ¡ng"}
        }
    ]

def mock_image_lookup_by_chunk_id(chunk_id: str) -> Optional[str]:
    """Giáº£ láº­p viá»‡c tra cá»©u áº£nh báº±ng chunk_id."""
    print(f"ğŸ–¼ï¸ >> Giáº£ láº­p VectorStore: Äang tra cá»©u áº£nh vá»›i chunk_id '{chunk_id}'...")
    if chunk_id == "chunk_xyz_789":
        # Giáº£ sá»­ tÃ¬m tháº¥y áº£nh tÆ°Æ¡ng á»©ng
        return "https://example.com/images/bach_thao_suong_on_gums.jpg"
    # Giáº£ sá»­ khÃ´ng tÃ¬m tháº¥y
    return None

def mock_image_search_by_entities(entities: dict) -> Optional[str]:
    """Giáº£ láº­p viá»‡c tÃ¬m kiáº¿m áº£nh báº±ng entities khi tra cá»©u tháº¥t báº¡i."""
    print(f"ğŸ–¼ï¸ >> Giáº£ láº­p VectorStore: Tra cá»©u tháº¥t báº¡i, chuyá»ƒn sang tÃ¬m kiáº¿m áº£nh báº±ng entities '{entities}'...")
    # Táº¡o query giÃ u mÃ´ táº£ tá»« entities vÃ  tÃ¬m kiáº¿m vector
    return "https://example.com/images/generic_medicinal_powder.jpg"

def mock_llm_generate_final_answer(question: str, context: List[dict], image_url: Optional[str]) -> str:
    """Giáº£ láº­p LLM Ä‘a phÆ°Æ¡ng thá»©c sinh cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng."""
    print("âœ¨ >> Giáº£ láº­p LLM: Äang tá»•ng há»£p vÃ  sinh cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng...")
    text_context = "\n".join([chunk['content'] for chunk in context])
    answer = f"Äá»ƒ tráº£ lá»i cÃ¢u há»i '{question}', báº¡n cÃ³ thá»ƒ tham kháº£o thÃ´ng tin sau: {text_context}."
    if image_url:
        answer += f"\n\náº¢nh minh há»a: {image_url}"
    return answer

# --- 3. Äá»‹nh nghÄ©a cÃ¡c Node cá»§a Graph ---

def analyze_query_node(state: GraphState) -> GraphState:
    """Node 1: PhÃ¢n tÃ­ch cÃ¢u há»i vÃ  trÃ­ch xuáº¥t entities."""
    print("\n--- BÆ¯á»šC 1: PHÃ‚N TÃCH QUERY ---")
    question = state.get("question")
    entities = mock_llm_extract_entities(question)
    return {**state, "entities": entities}

def enhanced_text_retrieval_node(state: GraphState) -> GraphState:
    """Node 2: Truy xuáº¥t vÄƒn báº£n tÄƒng cÆ°á»ng."""
    print("\n--- BÆ¯á»šC 2: TRUY XUáº¤T VÄ‚N Báº¢N ---")
    question = state.get("question")
    entities = state.get("entities")
    text_chunks = mock_text_hybrid_search(question, entities)
    if not text_chunks:
        return {**state, "error": "KhÃ´ng tÃ¬m tháº¥y vÄƒn báº£n nÃ o phÃ¹ há»£p."}
    return {**state, "text_chunks": text_chunks}

def image_lookup_node(state: GraphState) -> GraphState:
    """Node 3: Tra cá»©u áº£nh báº±ng chunk_id (Æ¯u tiÃªn 1)."""
    print("\n--- BÆ¯á»šC 3.1: TRUY XUáº¤T áº¢NH (Æ¯U TIÃŠN 1 - DÃ™NG CHUNK_ID) ---")
    text_chunks = state.get("text_chunks")
    if not text_chunks:
        return {**state, "image_url": None} # Bá» qua náº¿u khÃ´ng cÃ³ text
    
    top_chunk_id = text_chunks[0].get("chunk_id")
    image_url = mock_image_lookup_by_chunk_id(top_chunk_id)
    return {**state, "image_url": image_url}

def image_search_node(state: GraphState) -> GraphState:
    """Node 4: TÃ¬m kiáº¿m áº£nh báº±ng entities (PhÆ°Æ¡ng Ã¡n 2)."""
    print("\n--- BÆ¯á»šC 3.2: TRUY XUáº¤T áº¢NH (PHÆ¯Æ NG ÃN 2 - DÃ™NG ENTITIES) ---")
    entities = state.get("entities")
    image_url = mock_image_search_by_entities(entities)
    return {**state, "image_url": image_url}
    
def generate_answer_node(state: GraphState) -> GraphState:
    """Node 5: Sinh cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng."""
    print("\n--- BÆ¯á»šC 4: SINH CÃ‚U TRáº¢ Lá»œI ---")
    question = state.get("question")
    text_chunks = state.get("text_chunks")
    image_url = state.get("image_url")
    
    if state.get("error"):
         final_answer = f"ÄÃ£ cÃ³ lá»—i xáº£y ra: {state.get('error')}"
    else:
        final_answer = mock_llm_generate_final_answer(question, text_chunks, image_url)
    
    return {**state, "final_answer": final_answer}

# --- 4. Äá»‹nh nghÄ©a cÃ¡c cáº¡nh vÃ  Ä‘iá»u kiá»‡n ráº½ nhÃ¡nh (Edges) ---

def should_fallback_to_image_search(state: GraphState) -> str:
    """
    HÃ m quyáº¿t Ä‘á»‹nh: Náº¿u Ä‘Ã£ tÃ¬m tháº¥y áº£nh báº±ng chunk_id thÃ¬ Ä‘i Ä‘áº¿n bÆ°á»›c sinh cÃ¢u tráº£ lá»i.
    Náº¿u khÃ´ng, thá»±c hiá»‡n tÃ¬m kiáº¿m áº£nh báº±ng entities.
    """
    print("--- KIá»‚M TRA ÄIá»€U KIá»†N Ráº¼ NHÃNH ---")
    if state.get("image_url"):
        print("âœ… ÄÃ£ tÃ¬m tháº¥y áº£nh báº±ng chunk_id. Chuyá»ƒn Ä‘áº¿n bÆ°á»›c sinh cÃ¢u tráº£ lá»i.")
        return "generate_answer"
    else:
        print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y áº£nh. Chuyá»ƒn sang phÆ°Æ¡ng Ã¡n 2: tÃ¬m kiáº¿m báº±ng entities.")
        return "image_search"

# --- 5. XÃ¢y dá»±ng vÃ  Compile Graph ---

def create_smart_rag_graph() -> "CompiledGraph":
    workflow = StateGraph(GraphState)

    # ThÃªm cÃ¡c node vÃ o graph
    workflow.add_node("analyze_query", analyze_query_node)
    workflow.add_node("enhanced_text_retrieval", enhanced_text_retrieval_node)
    workflow.add_node("image_lookup", image_lookup_node)
    workflow.add_node("image_search", image_search_node)
    workflow.add_node("generate_answer", generate_answer_node)

    # Káº¿t ná»‘i cÃ¡c node
    workflow.set_entry_point("analyze_query")
    workflow.add_edge("analyze_query", "enhanced_text_retrieval")
    workflow.add_edge("enhanced_text_retrieval", "image_lookup")
    
    # ThÃªm cáº¡nh Ä‘iá»u kiá»‡n sau bÆ°á»›c tra cá»©u áº£nh
    workflow.add_conditional_edges(
        "image_lookup",
        should_fallback_to_image_search,
        {
            "image_search": "image_search",
            "generate_answer": "generate_answer",
        }
    )
    
    workflow.add_edge("image_search", "generate_answer")
    workflow.add_edge("generate_answer", END)

    # Compile graph Ä‘á»ƒ sáºµn sÃ ng sá»­ dá»¥ng
    return workflow.compile()

# --- 6. Cháº¡y Pipeline ---

if __name__ == "__main__":
    # Khá»Ÿi táº¡o graph
    app = create_smart_rag_graph()

    # Äá»‹nh nghÄ©a cÃ¢u há»i Ä‘áº§u vÃ o
    inputs = {"question": "BÃ¡ch tháº£o sÆ°Æ¡ng dÃ¹ng Ä‘á»ƒ chá»¯a cháº£y mÃ¡u káº½ rÄƒng nhÆ° tháº¿ nÃ o?"}
    
    # Cháº¡y pipeline vÃ  xem cÃ¡c bÆ°á»›c thá»±c thi
    print("ğŸš€ Báº®T Äáº¦U CHáº Y PIPELINE RAG ÄA PHÆ¯Æ NG THá»¨C ğŸš€")
    for output in app.stream(inputs, stream_mode="values"):
        # `stream_mode="values"` sáº½ tráº£ vá» state sau má»—i bÆ°á»›c
        print("\n" + "="*50)
        print("Tráº¡ng thÃ¡i hiá»‡n táº¡i cá»§a Graph:")
        print(output)
        print("="*50)

    print("\nğŸ PIPELINE HOÃ€N Táº¤T! ğŸ")
    print("\nCÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng lÃ :")
    print(output.get("final_answer"))