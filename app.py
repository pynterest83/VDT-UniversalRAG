import gradio as gr
from pipeline import create_enhanced_rag_graph, run_image_generation
import os
from PIL import Image
import base64
from io import BytesIO

# Initialize pipeline globally
app = create_enhanced_rag_graph()

# Global state to store current pipeline result
current_state = None

def process_medical_question(message, progress=gr.Progress()):
    """Process medical question with detailed step-by-step output"""
    global current_state
    
    if not message.strip():
        return "Vui l√≤ng nh·∫≠p c√¢u h·ªèi.", "", [], "", "", False
    
    inputs = {"question": message}
    
    step_details = []
    final_answer = ""
    available_images = []
    context_info = ""
    
    progress(0, desc="Kh·ªüi t·∫°o pipeline...")
    
    step_count = 0
    total_steps = 6
    
    for output in app.stream(inputs, stream_mode="values"):
        step_count += 1
        progress(step_count / total_steps, desc=f"B∆∞·ªõc {step_count}/{total_steps}")
        
        if output.get("initial_chunks") and not any("B∆Ø·ªöC 1" in detail for detail in step_details):
            initial_chunks = output["initial_chunks"]
            step_details.append(f"‚úÖ **B∆Ø·ªöC 1: T√åM KI·∫æM CONTEXT BAN ƒê·∫¶U**")
            step_details.append(f"   üìÑ T√¨m th·∫•y {len(initial_chunks)} ƒëo·∫°n context t·ª´ vector store")
            step_details.append(f"   üîç Model embedding: bge-m3-v3")
            step_details.append("")
        
        if output.get("reranked_chunks") and not any("B∆Ø·ªöC 2" in detail for detail in step_details):
            reranked_chunks = output["reranked_chunks"]
            step_details.append(f"‚úÖ **B∆Ø·ªöC 2: RERANK CONTEXT V·ªöI VIETNAMESE RERANKER**")
            step_details.append(f"   üîÑ ƒê√£ rerank v√† ch·ªçn top {len(reranked_chunks)} context")
            step_details.append(f"   ü§ñ Model: AITeamVN/Vietnamese_Reranker")
            
            for i, chunk in enumerate(reranked_chunks[:3]):
                score = chunk.get('rerank_score', 0)
                preview = chunk['content'][:80] + "..." if len(chunk['content']) > 80 else chunk['content']
                step_details.append(f"      {i+1}. Score: {score:.4f} - {preview}")
            step_details.append("")
        
        if output.get("selected_contexts") and not any("B∆Ø·ªöC 3" in detail for detail in step_details):
            selected_contexts = output["selected_contexts"]
            step_details.append(f"‚úÖ **B∆Ø·ªöC 3: GPT-4O L·ª∞A CH·ªåN CONTEXT T·ªêT NH·∫§T**")
            step_details.append(f"   üéØ ƒê√£ ch·ªçn {len(selected_contexts)} context t·ª´ {len(output.get('reranked_chunks', []))} context")
            step_details.append(f"   üß† AI ph√¢n t√≠ch v√† ch·ªçn context ph√π h·ª£p nh·∫•t")
            
            for i, ctx in enumerate(selected_contexts):
                preview = ctx['content'][:100] + "..." if len(ctx['content']) > 100 else ctx['content']
                rerank_score = ctx.get('rerank_score', 0)
                step_details.append(f"      Context {i+1} (Score: {rerank_score:.4f}): {preview}")
            step_details.append("")
        
        if output.get("answer") and not any("B∆Ø·ªöC 4" in detail for detail in step_details):
            answer = output["answer"]
            word_count = len(answer.split())
            step_details.append(f"‚úÖ **B∆Ø·ªöC 4: GPT-4O SINH C√ÇU TR·∫¢ L·ªúI**")
            step_details.append(f"   üí¨ ƒê√£ sinh c√¢u tr·∫£ l·ªùi ({word_count} t·ª´)")
            step_details.append(f"   üéØ D·ª±a tr√™n {len(output.get('selected_contexts', []))} context ƒë∆∞·ª£c ch·ªçn")
            step_details.append("")
        
        if output.get("available_images") and not any("B∆Ø·ªöC 5" in detail for detail in step_details):
            available_images_data = output["available_images"]
            step_details.append(f"‚úÖ **B∆Ø·ªöC 5: T√åM KI·∫æM 5 ·∫¢NH MINH H·ªåA**")
            step_details.append(f"   üñºÔ∏è T√¨m th·∫•y {len(available_images_data)} ·∫£nh li√™n quan")
            step_details.append(f"   üì∏ Model embedding: bge-m3-image")
            
            for i, img in enumerate(available_images_data[:3]):
                step_details.append(f"      {i+1}. Score: {img.get('score', 0):.4f} - {img.get('caption', 'N/A')[:60]}...")
            step_details.append("")
    
    final_output = output
    current_state = final_output
    
    if final_output:
        final_answer = final_output.get("answer", "")
        available_images_data = final_output.get("available_images", [])
        available_images = process_available_images(available_images_data)
        context_info = create_context_summary(final_output)
    else:
        final_answer = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y."
    
    step_display = "\n".join(step_details)
    show_image_selection = len(available_images) > 0
    
    return final_answer, step_display, available_images, context_info, "", show_image_selection

def process_available_images(available_images_data):
    """Process image information to display in Gradio"""
    images = []
    
    for img_info in available_images_data:
        image_path = img_info.get('image_path')
        image_name = img_info.get('image_name')
        
        loaded_image = None
        actual_path = None
        
        if image_path and os.path.isfile(image_path):
            loaded_image = Image.open(image_path)
            actual_path = image_path
        else:
            possible_paths = [
                f"images/{image_name}" if image_name else None,
                f"datasets/images/{image_name}" if image_name else None,
                f"./images/{image_name}" if image_name else None,
            ]
            
            for path in possible_paths:
                if path and os.path.isfile(path):
                    try:
                        loaded_image = Image.open(path)
                        actual_path = path
                        break
                    except Exception:
                        continue
        
        if loaded_image and actual_path:
            caption = (
                f"Score: {img_info.get('score', 0):.4f}\n"
                f"{img_info.get('caption', '·∫¢nh li√™n quan')}"
            )
            images.append((actual_path, caption))
    
    return images

def select_existing_image(evt: gr.SelectData):
    """Handle selection of existing image from gallery"""
    global current_state
    
    if not current_state or not current_state.get("available_images"):
        return "Kh√¥ng c√≥ ·∫£nh ƒë·ªÉ ch·ªçn.", None
    
    selected_index = evt.index
    available_images = current_state["available_images"]
    
    if 0 <= selected_index < len(available_images):
        selected_image = available_images[selected_index]
        
        current_state["selected_image"] = selected_image
        current_state["user_choice"] = "select_existing"
        
        final_result = finalize_with_selected_image(current_state)
        selected_img = load_single_image(selected_image)
        
        return final_result["final_answer"], selected_img
    
    return "L·ªói khi ch·ªçn ·∫£nh.", None

def generate_new_image():
    """Generate new image using AI"""
    global current_state
    
    if not current_state:
        return "Vui l√≤ng ƒë·∫∑t c√¢u h·ªèi tr∆∞·ªõc.", None
    
    result = run_image_generation(current_state)
    generated_image = result.get("generated_image")
    
    if generated_image:
        current_state["generated_image"] = generated_image
        current_state["user_choice"] = "generate_new"
        
        final_result = finalize_with_selected_image(current_state)
        generated_img = load_single_image(generated_image)
        
        return final_result["final_answer"], generated_img
    else:
        return "Kh√¥ng th·ªÉ t·∫°o ·∫£nh m·ªõi. Vui l√≤ng th·ª≠ l·∫°i.", None

def finalize_with_selected_image(state):
    """Create final answer with selected image"""
    from pipeline import finalize_answer_node
    return finalize_answer_node(state)

def load_single_image(image_info):
    """Load a single image for display"""
    if not image_info:
        return None
        
    image_path = image_info.get('image_path')
    image_name = image_info.get('image_name')
    
    if image_path and os.path.isfile(image_path):
        return Image.open(image_path)
    
    possible_paths = [
        f"images/{image_name}" if image_name else None,
        f"datasets/images/{image_name}" if image_name else None,
        f"./images/{image_name}" if image_name else None,
        f"imgs/{image_name}" if image_name else None,
    ]
    
    for path in possible_paths:
        if path and os.path.isfile(path):
            try:
                return Image.open(path)
            except Exception:
                continue
    
    return None

def create_context_summary(output):
    """Create summary of context and processing information"""
    summary_parts = []
    
    question = output.get("question", "N/A")
    summary_parts.append(f"**C√ÇU H·ªéI:** {question}")
    summary_parts.append("")
    
    initial_chunks = output.get("initial_chunks", [])
    reranked_chunks = output.get("reranked_chunks", [])
    selected_contexts = output.get("selected_contexts", [])
    
    summary_parts.append("**TH·ªêNG K√ä CONTEXT:**")
    summary_parts.append(f"‚Ä¢ Context ban ƒë·∫ßu: {len(initial_chunks)} ƒëo·∫°n")
    summary_parts.append(f"‚Ä¢ Context sau rerank: {len(reranked_chunks)} ƒëo·∫°n")
    summary_parts.append(f"‚Ä¢ Context ƒë∆∞·ª£c ch·ªçn: {len(selected_contexts)} ƒëo·∫°n")
    summary_parts.append("")
    
    if selected_contexts:
        summary_parts.append("**CONTEXT ƒê∆Ø·ª¢C S·ª¨ D·ª§NG:**")
        for i, ctx in enumerate(selected_contexts):
            score = ctx.get('rerank_score', 0)
            content_preview = ctx['content'][:200] + "..." if len(ctx['content']) > 200 else ctx['content']
            summary_parts.append(f"**Context {i+1}** (Rerank Score: {score:.4f})")
            summary_parts.append(f"{content_preview}")
            summary_parts.append("")
    
    available_images = output.get("available_images", [])
    if available_images:
        summary_parts.append("**TH√îNG TIN ·∫¢NH C√ì S·∫¥N:**")
        summary_parts.append(f"‚Ä¢ S·ªë l∆∞·ª£ng ·∫£nh t√¨m th·∫•y: {len(available_images)}")
        for i, img in enumerate(available_images[:3]):
            summary_parts.append(f"‚Ä¢ ·∫¢nh {i+1}: Score {img.get('score', 0):.4f} - {img.get('caption', 'N/A')[:60]}...")
        summary_parts.append("")
    
    return "\n".join(summary_parts)

def create_interface():
    """Create the main Gradio interface"""
    
    with gr.Blocks(title="üè• Medical RAG Chatbot", theme=gr.themes.Soft()) as demo:
        
        gr.Markdown("""
        # üè• Medical RAG Chatbot v·ªõi GPT-4o + AI Image Generation
        
        **H·ªá th·ªëng h·ªèi ƒë√°p y t·∫ø th√¥ng minh** s·ª≠ d·ª•ng:
        - üîç **BGE-M3** cho t√¨m ki·∫øm context 
        - üáªüá≥ **Vietnamese Reranker** cho s·∫Øp x·∫øp l·∫°i
        - üß† **GPT-4o** cho l·ª±a ch·ªçn context v√† tr·∫£ l·ªùi
        - üñºÔ∏è **BGE-M3-Image** cho t√¨m ki·∫øm ·∫£nh minh h·ªça
        - üé® **Azure OpenAI Image Generation** cho t·∫°o ·∫£nh m·ªõi
        
        ƒê·∫∑t c√¢u h·ªèi v·ªÅ y t·∫ø, thu·ªëc, b·ªánh, th·∫£o d∆∞·ª£c, v√† nh·∫≠n c√¢u tr·∫£ l·ªùi chi ti·∫øt k√®m h√¨nh ·∫£nh!
        """)
        
        with gr.Row():
            with gr.Column(scale=2):
                question_input = gr.Textbox(
                    label="üí¨ C√¢u h·ªèi y t·∫ø",
                    placeholder="VD: Thu·ªëc Paracetamol c√≥ t√°c d·ª•ng ph·ª• g√¨?",
                    lines=2
                )
                
                with gr.Row():
                    submit_btn = gr.Button("üöÄ H·ªèi", variant="primary", scale=2)
                    clear_btn = gr.Button("üóëÔ∏è X√≥a", scale=1)
                
                gr.Examples(
                    examples=[
                        "B√°ch th·∫£o s∆∞∆°ng d√πng ƒë·ªÉ ch·ªØa ch·∫£y m√°u k·∫Ω rƒÉng nh∆∞ th·∫ø n√†o?",
                        "Thu·ªëc Paracetamol c√≥ t√°c d·ª•ng g√¨ v√† li·ªÅu d√πng ra sao?",
                        "Calci D Hasan c√≥ th·ªÉ g√¢y ·∫£nh h∆∞·ªüng g√¨ ƒë·∫øn b·ªánh nh√¢n m·∫Øc b·ªánh l√Ω n·ªÅn?",
                        "C√¢y l√° l·ªët c√≥ c√¥ng d·ª•ng g√¨ trong y h·ªçc c·ªï truy·ªÅn?",
                        "Vitamin D thi·∫øu h·ª•t c√≥ tri·ªáu ch·ª©ng g√¨?",
                    ],
                    inputs=question_input
                )
            
            with gr.Column(scale=1):
                final_image_output = gr.Image(
                    label="üñºÔ∏è ·∫¢nh ƒë∆∞·ª£c ch·ªçn",
                    height=300
                )
        
        with gr.Row():
            with gr.Column():
                answer_output = gr.Textbox(
                    label="üí° C√¢u tr·∫£ l·ªùi",
                    lines=8,
                    max_lines=15
                )
            
            with gr.Column():
                steps_output = gr.Textbox(
                    label="‚öôÔ∏è C√°c b∆∞·ªõc th·ª±c hi·ªán",
                    lines=8,
                    max_lines=15
                )
        
        with gr.Row(visible=False) as image_selection_row:
            with gr.Column():
                gr.Markdown("## üñºÔ∏è Ch·ªçn ·∫£nh minh h·ªça")
                gr.Markdown("**Ch·ªçn 1 trong 5 ·∫£nh b√™n d∆∞·ªõi ho·∫∑c t·∫°o ·∫£nh m·ªõi:**")
                
                available_images_gallery = gr.Gallery(
                    label="üì∑ ·∫¢nh c√≥ s·∫µn (click ƒë·ªÉ ch·ªçn)",
                    show_label=True,
                    elem_id="gallery",
                    columns=5,
                    rows=1,
                    height=200,
                    allow_preview=True
                )
                
                with gr.Row():
                    generate_new_btn = gr.Button("üé® T·∫°o ·∫£nh m·ªõi v·ªõi AI", variant="secondary")
        
        with gr.Accordion("üìä Chi ti·∫øt Context & Th√¥ng tin", open=False):
            context_output = gr.Textbox(
                label="Th√¥ng tin chi ti·∫øt",
                lines=10,
                max_lines=20
            )
        
        image_selection_visible = gr.State(False)
        
        def submit_question(question):
            if not question.strip():
                return "Vui l√≤ng nh·∫≠p c√¢u h·ªèi.", "", [], "", None, gr.update(visible=False)
            
            answer, steps, images, context, final_img_ignored, show_selection = process_medical_question(question)
            
            return (
                answer, 
                steps, 
                images, 
                context, 
                None,
                gr.update(visible=show_selection)
            )
        
        def clear_all():
            global current_state
            current_state = None
            return "", "", "", [], "", None, gr.update(visible=False)
        
        submit_btn.click(
            fn=submit_question,
            inputs=[question_input],
            outputs=[answer_output, steps_output, available_images_gallery, context_output, final_image_output, image_selection_row]
        )
        
        question_input.submit(
            fn=submit_question,
            inputs=[question_input],
            outputs=[answer_output, steps_output, available_images_gallery, context_output, final_image_output, image_selection_row]
        )
        
        available_images_gallery.select(
            fn=select_existing_image,
            outputs=[answer_output, final_image_output]
        )
        
        generate_new_btn.click(
            fn=generate_new_image,
            outputs=[answer_output, final_image_output]
        )
        
        clear_btn.click(
            fn=clear_all,
            outputs=[question_input, answer_output, steps_output, available_images_gallery, context_output, final_image_output, image_selection_row]
        )
        
        gr.Markdown("""
        ---
        **üîß Technical Stack:** BGE-M3 ‚Ä¢ Vietnamese Reranker ‚Ä¢ GPT-4o ‚Ä¢ Qdrant ‚Ä¢ LangGraph ‚Ä¢ Azure OpenAI Image Generation
        
        **‚ö†Ô∏è L∆∞u √Ω:** Th√¥ng tin ch·ªâ mang t√≠nh tham kh·∫£o. Vui l√≤ng tham kh·∫£o √Ω ki·∫øn b√°c sƒ© cho ch·∫©n ƒëo√°n v√† ƒëi·ªÅu tr·ªã ch√≠nh x√°c.
        """)
    
    return demo

if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        share=True,
        server_name="localhost",
        server_port=7860
    )
